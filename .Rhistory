chk2=subset(chk,chk$Time<8 & chk$Diet<3)
chk2=subset(chk,chk$Time<8 & chk$Diet!=3 & chk$Diet!=4)
chk2
View(chk2)
View(ChickWeight)
chk2=subset(chk,chk$Time<8 & chk$Chick=1:4 | chk$Chick=21:24 | chk$Chick=31:34 | chk$Chick=41:44)
chk2=subset(chk,chk$Time<8 & chk$Chick[1:4] | chk$Chick=21:24 | chk$Chick=31:34 | chk$Chick=41:44)
chk2=subset(chk,chk$Time<8 & chk$Chick[1:4] | chk$Chick[21:24] | chk$Chick[31:34] | chk$Chick[41:44])
chk2=subset(chk,chk$Time<8)
chk3=subset(chk2,chk$Chick[1:4] | chk$Chick[21:24] | chk$Chick[31:34] | chk$Chick[41:44])
chk3=subset(chk2,chk$Chick[1:4, 21:24,31:34,41:44)
chk3=subset(chk2,chk$Chick[1:4,21:24,31:34,41:44])
?subset
?select
?select
chk %>%
filter(Time<8) %>%
filter(Chick=="1"|Chick=="2"|Chick=="3"|Chick=="21"|Chick=="22"|Chick=="23"|Chick=="31"|Chick=="32"|Chick=="33"|Chick=="41"|Chick=="42"|Chick=="43"|)
chk %>%
filter(Time<8) %>%
filter(Chick=="1"|Chick=="2"|Chick=="3"|Chick=="21"|Chick=="22"|Chick=="23"|Chick=="31"|Chick=="32"|Chick=="33"|Chick=="41"|Chick=="42"|Chick=="43")
chk3=chk %>%
filter(Time<8) %>%
filter(Chick=="1"|Chick=="2"|Chick=="3"|Chick=="21"|Chick=="22"|Chick=="23"|Chick=="31"|Chick=="32"|Chick=="33"|Chick=="41"|Chick=="42"|Chick=="43")
View(chk3)
write.table(chk3, "clipboard", sep="\t")
data("islands")
islands
View(islands)
data("mtcars")
mtcars
View(mtcars)
write.table(mtcars, "clipboard", sep="\t", row.names=T)
data("Nile")
Nile
data("LifeCycleSavings")
LifeCycleSavings
head(LifeCycleSavings)
data("USPersonalExpenditures")
data("USPersonalExpenditure")
USPersonalExpenditure
?USPersonalExpenditure
?attenu
?crimtab
data("crimtab")
crimtab
head(crimtab)
?sleep
data("sunspots")
sunspots
head(sunspots)
data("USArrests")
head(USArrests)
data("USAccDeaths")
USAccDeaths
data("UCBAdmissions")
UCBAdmissions
head(UCBAdmissions)
View(UCBAdmissions)
data("attitude")
attitude
head(attitude)
?attitude
data("WorldPhones")
WorldPhones
?WorldPhones
write.table(WorldPhones, "clipboard", sep="\t", row.names=T)
?mtcars
library(DiagrammeR)
library(devtools)
library(DiagrammeRsvg)
grViz("digraph graph2 {
graph [layout=dot,fontsize=12]
node [shape=circle]
a; b; c; d; e
node[shape=square]
f; g
a->b a->c c->d c->e e->f e->g
}")
grViz("digraph graph2 {
graph [layout=dot,fontsize=12]
node [shape=circle]
Voicing; Interlocutor; Character; Generic; Real Past Events; Personal Stories
node[shape=square]
Current Thoughts; Hypothetical; Future; Generic Group; Generic Situation; Distant Stories; Second-Hand Stories; Immediate Stories; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Current Thoughts Character->Hypothetical Character->Future Character->Generic Character->Real Past Events Generic->Generic Group Generic->Generic Situation Real Past Events->Distant Stories Real Past Events->Second-Hand Stories Real Past Events->Personal Stories Personal Stories->Immediate Stories Personal Stories->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot,fontsize=12]
node [shape=circle]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot,fontsize=12]
node [shape=circle, fixedsize=TRUE]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot]
node [shape=circle, fixedsize=TRUE]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph
node [shape=circle, fixedsize=TRUE]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot, overlap=FALSE]
node [shape=circle, fixedsize=TRUE]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot, overlap=FALSE]
node [shape=circle, fixedsize=TRUE, fontsize=10]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot, overlap=FALSE]
node [shape=circle, fixedsize=TRUE, fontsize=8]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot, overlap=FALSE]
node [shape=circle, fixedsize=TRUE, fontsize=8]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE, peripheries=2]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot, overlap=FALSE]
node [shape=circle, fixedsize=TRUE, fontsize=8]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE, peripheries=2, fillcolor=blue]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot, overlap=FALSE]
node [shape=circle, fixedsize=TRUE, fontsize=8]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE, peripheries=2, color=blue]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
grViz("digraph graph2 {
graph [layout=dot, overlap=FALSE]
node [shape=circle, fixedsize=TRUE, fontsize=8, color=green]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE, peripheries=2, color=blue]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
getwd()
grViz("digraph graph2 {
graph [layout=dot, overlap=FALSE]
node [shape=circle, fixedsize=TRUE, fontsize=6, color=green]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE, peripheries=2, color=blue]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
export_graph(graph, file_name = "graph.png", file_type = png)
graph=grViz("digraph graph2 {
graph [layout=dot, overlap=FALSE]
node [shape=circle, fixedsize=TRUE, fontsize=6, color=green]
Voicing; Interlocutor; Character; Generic; Past; Personal
node[shape=square,fixedsize=TRUE, peripheries=2, color=blue]
Thoughts; Hypothetical; Future; Group; Situation; Distant; SecondHand; Immediate; Anecdotes
Voicing->Interlocutor Voicing->Character Interlocutor->Thoughts Character->Hypothetical Character->Future Character->Generic Character->Past Generic->Group Generic->Situation Past->Distant Past->SecondHand Past->Personal Personal->Immediate Personal->Anecdotes
}")
export_graph(graph, file_name = "graph.png", file_type = png)
getwd()
library(devtools)
create_package("C:/Users/Leah/Desktop/discnetR")
getwd()
setwd("C:Users/Leah/Desktop")
library(tidyverse)
read.csv("C:/Users/Leah/Desktop/fatal-police-shootings-data.txt")
data <- read.csv("C:/Users/Leah/Desktop/fatal-police-shootings-data.txt")
head(data)
data[city=="Mobile"]
data[data$city=="Mobile"]
data[data$city=="Mobile",]
head(data)
data[data$armed=="unarmed",]
unarmed <- data[data$armed=="unarmed",]
sum(unarmed)
summary(unarmed)
data$date
?date
?lubridate
ymd(data$date)
library(lubridate)
ymd(data$date)
?lubridate
year(ymd(data$date))
year <- year(ymd(data$date))
mutate(data, year)
data %>% group_by(year)
data <- mutate(data, year)
data %>% group_by(year)
data %>% group_by(year) %>% sum()
data %>% group_by(year) %>% n()
data %>% group_by(year) %>% summarise()
data %>% group_by(year) %>% summarise(n())
setwd("C:Users/Leah/Desktop")
getwd()
setwd("C:Users/Leah/Desktop")
library(tidyverse)
library(lubridate)
data <- read.csv("C:/Users/Leah/Desktop/fatal-police-shootings-data.txt")
mobile <- data[data$city=="Mobile",]
mobile
getwd()
setwd("C:Users/Leah/Desktop")
data <- read.csv("C:/Users/Leah/Downloads/wals-master.zip")
head(data)
data <- read.csv("Contributions.csv")
head(data)
#As always, start by setting up the working directory
getwd()
setwd("C:Users/Leah/RforLing")
getwd()
setwd("C:/Users/Leah/Desktop/RforLing")
library(tidyverse)
library(languageR)
### THE BASICS: MEAN AND VARIANCE
english %>% summarize(mean(lexdecRT))
### THE BASICS: MEAN AND VARIANCE
english %>% summarize(mean(RTlexdec))
english %>% summarize(sd(RTlexdec))
sapply(english, mean)
#other useful summarize() statistics: var, min, max, median, range, quantile
#can get those one at a time, as above
#or "summary()" gives several:
summary(english$RTlexdec)
### THE BASICS: COMPARING VALUES
english %>% table(RTlexdec, AgeSubject)
### THE BASICS: COMPARING VALUES
table(english, RTlexdec, AgeSubject)
### THE BASICS: COMPARING VALUES
table(english$RTlexdec, english$AgeSubject)
sapply(english, mean) #where do the NA's appear?
### THE BASICS: COMPARING VALUES
table(english$CV, english$Voice)
prop.table(english$CV, english$Voice)
prop.table(table1)
### THE BASICS: COMPARING VALUES
table1 <- table(english$CV, english$Voice)
prop.table(table1)
#Three categorical variables
table(english$CV, english$Voice, english$WordCategory)
#Three categorical variables
table2 <- table(english$CV, english$Voice, english$WordCategory)
ftable(table2)
###BASICS: DISTRIBUTIONS
#A "distribution" is the pattern of what results you get following certain probability rules
#For example, say your experiment is "flip a fair coin 100 times and count the number of heads." The first time you do that, you get 47 heads. The second time, 60 heads. The third time, 54 heads. The fourth time, 32 heads. And so on.
#If you repeat this experiment many many times, most of the results are going to be near 50 heads. It has a binomial distribution -- this kind of experiment follows the binomial rules. But we usually approximate this with a normal distribution. That's the hill-shaped one. We expect most of the results to be near 50, some of the results to be a little further away from 50, and very few results to be far away from 50.
#rn and graph
?runif()
###BASICS: DISTRIBUTIONS
#A "distribution" is the pattern of what results you get following certain probability rules
#For example, say your experiment is "flip a fair coin 100 times and count the number of heads." The first time you do that, you get 47 heads. The second time, 60 heads. The third time, 54 heads. The fourth time, 32 heads. And so on.
#If you repeat this experiment many many times, most of the results are going to be near 50 heads. It has a binomial distribution -- this kind of experiment follows the binomial rules. But we usually approximate this with a normal distribution. That's the hill-shaped one. We expect most of the results to be near 50, some of the results to be a little further away from 50, and very few results to be far away from 50.
#rn and graph
rbinom(n=1, size=100, prob=0.5)
rbinom(n=1000, size=100, prob=0.5)
plot(rbinom(n=1000, size=100, prob=0.5))
?plot
plot(rbinom(n=1000, size=100, prob=0.5), type="h")
plot(rbinom(n=1000, size=100, prob=0.5), type="s")
rbinom(n=1, size=100, prob=0.5) %>% summarize(freq=n()) %>% plot()
rbinom(n=1, size=100, prob=0.5) %>% n()
rbinom(n=1, size=100, prob=0.5) %>% count()
rbinom(n=1, size=100, prob=0.5) %>% freq()
rbinom(n=1, size=100, prob=0.5) %>% frequency()
rbinom(n=1, size=100, prob=0.5) %>% hist()
hist(rbinom(n=1, size=100, prob=0.5))
hist(rbinom(n=1000, size=100, prob=0.5))
hist(rbinom(n=1000, size=100, prob=0.5))
?runif
#Say your second experiment is "roll a fair six-sided die 60 times and tally what numbers come up." You'd expect each number to come up around (but probably not exactly) 10 times.
ceiling(runif(n=60, min=0, max=6))
hist(ceiling(runif(n=60, min=0, max=6)))
hist(ceiling(runif(n=60, min=0, max=6)))
hist(ceiling(runif(n=60, min=0, max=6)))
hist(ceiling(runif(n=60, min=0, max=6)))
hist(ceiling(runif(n=60, min=-1, max=6)))
hist(ceiling(runif(n=60, min=-1, max=6)))
hist(ceiling(runif(n=60, min=-1, max=6)))
hist(ceiling(runif(n=60, min=-1, max=6)))
#Say your second experiment is "roll a fair six-sided die 60 times and tally what numbers come up." You'd expect each number to come up around (but probably not exactly) 10 times.
sample(x=1:6, size=60)
#Say your second experiment is "roll a fair six-sided die 60 times and tally what numbers come up." You'd expect each number to come up around (but probably not exactly) 10 times.
sample(x=1:6, n=60)
#Say your second experiment is "roll a fair six-sided die 60 times and tally what numbers come up." You'd expect each number to come up around (but probably not exactly) 10 times.
sample(x=1:6, size=60)
#Say your second experiment is "roll a fair six-sided die 60 times and tally what numbers come up." You'd expect each number to come up around (but probably not exactly) 10 times.
sample(x=1:6, size=60, replace=TRUE)
hist(sample(x=1:6, size=60, replace=TRUE))
hist(sample(x=1:6, size=60, replace=TRUE))
hist(sample(x=1:6, size=60, replace=TRUE))
plot(sample(x=1:6, size=60, replace=TRUE))
plot(rbinom(n=1000, size=100, prob=0.5), type="s")
plot(sample(x=1:6, size=60, replace=TRUE), type="s")
plot(sample(x=1:6, size=60, replace=TRUE), type="b")
?plot
plot(sample(x=1:6, size=60, replace=TRUE), type="h")
plot(table(sample(x=1:6, size=60, replace=TRUE)), type="h")
plot(table(sample(x=1:6, size=60, replace=TRUE)), type="h")
plot(table(sample(x=1:6, size=60, replace=TRUE)), type="h")
plot(table(sample(x=1:6, size=60, replace=TRUE)), type="h")
table(sample(x=1:6, size=60, replace=TRUE))
table(sample(x=1:6, size=60, replace=TRUE))
?sample
#trying to make R save 1,000 die-rolling experiments of 60 throws each is surprisingly annoying
#we'll do not-quite-the-same-thing and just roll 60,000 times
plot(table(sample(x=1:6, size=60000, replace=TRUE)), type="h")
#trying to make R save 1,000 die-rolling experiments of 60 throws each is surprisingly annoying
#we'll do not-quite-the-same-thing and just roll 60,000 times
hist(table(sample(x=1:6, size=60000, replace=TRUE)))
#trying to make R save 1,000 die-rolling experiments of 60 throws each is surprisingly annoying
#we'll do not-quite-the-same-thing and just roll 60,000 times
plot(table(sample(x=1:6, size=60000, replace=TRUE)), type="h")
#Here's the really important (and tricky) part: it's not the situation, the rolling of dice or flipping of coins, that matters. It's the question you're asking ABOUT that situation.
#With the die roll, I can change my question to "how often do I roll a 1"? And THAT is a binomial question again (we expect it to happen about 1/6 of the time)
hist(rbinom(n=1000, size=60, prob=(1/6)))
### TEST 1: T-TEST
#A t-test compares data to "Student's t" distibution (not just for students, the guy who invented it was named Student). This is like a normal distribution but has fatter tails, which means it's more likely than in a normal distribution to sometimes get results far away from the mean.
?rnorm()
### TEST 1: T-TEST
#A t-test compares data to "Student's t" distibution (not just for students, the guy who invented it was named Student). This is like a normal distribution but has fatter tails, which means it's more likely than in a normal distribution to sometimes get results far away from the mean.
hist(rnorm(100, mean=0, sd=1))
### TEST 1: T-TEST
#A t-test compares data to "Student's t" distibution (not just for students, the guy who invented it was named Student). This is like a normal distribution but has fatter tails, which means it's more likely than in a normal distribution to sometimes get results far away from the mean.
hist(rnorm(100, mean=0, sd=1))
### TEST 1: T-TEST
#A t-test compares data to "Student's t" distibution (not just for students, the guy who invented it was named Student). This is like a normal distribution but has fatter tails, which means it's more likely than in a normal distribution to sometimes get results far away from the mean.
hist(rnorm(100, mean=0, sd=1))
hist(rt(n=100))
hist(rt(n=100), df=1)
hist(rt(n=100, df=1))
hist(rt(n=100, df=5))
hist(rt(n=100, df=5))
hist(rt(n=100, df=5))
hist(rt(n=100, df=5))
#We use the Student's t-distribution when we think the data is probably normal, but we're sampling from something complicated so we can't be 100% sure.
#The main way we use this is for the t-test. If we have two normally distributed variables and they have different means, the t-test tells us whether it's likely that the difference in their means is just random chance.
#Let's stay with coin flips for an example. Say we have a new coin, Coin X, and we don't know if it's fair or not. We flip it 100 times and get these results:
rbinom(n=100,size=1,prob=0.3)
CoinX <- c(0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1)
#Is this likely to be a fair coin? What's the mean here?
mean(CoinX)
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, rbinom(n=100,size=1,prob=0.5))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, rbinom(n=100,size=1,prob=0.5))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, rbinom(n=100,size=1000,prob=0.5))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, rbinom(n=100,size=1,prob=0.5))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, rbinom(n=100,size=1,prob=0.5))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, rbinom(n=100,size=1,prob=0.5))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, rbinom(n=100,size=1,prob=0.5))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, 0.5)
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, (rbinom(n=100,size=1000,prob=0.5)/1000)
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, (rbinom(n=100,size=1000,prob=0.5)/1000)
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, (rbinom(n=100,size=1000,prob=0.5)/1000))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. But is it very likely? Let's t-test to find out.
t.test(CoinX, (rbinom(n=100,size=1000,prob=0.5)/1000))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. That's our null hypothesis here:  Coin X is *really* a fair coin (mean=0.5), and the results we got (mean=0.35) are from chance. But is that very likely? Let's t-test to find out.
t.test(CoinX, (rbinom(n=100,size=100,prob=0.5)/1000))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. That's our null hypothesis here:  Coin X is *really* a fair coin (mean=0.5), and the results we got (mean=0.35) are from chance. But is that very likely? Let's t-test to find out.
t.test(CoinX, (rbinom(n=100,size=100,prob=0.5)/100))
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. That's our null hypothesis here:  Coin X is *really* a fair coin (mean=0.5), and the results we got (mean=0.35) are from chance. But is that very likely? Let's t-test to find out.
t.test(CoinX, (rbinom(n=100,size=100,prob=0.5)/100))
#The p-value is small, around 0.002. So there's not a very high chance that we would get a mean of 0.35 in one experiment from a coin that was really fair. Coin X is very unlikely to be a fair coin. We can reject the null hypothesis that Coin X has the same mean as a fair coin. (If we were doing this for real, we would want to do more than one experiment.)
#Let's try it with linguistics data. Going back to the "english" dataset, there are are two groups of subjects: young and old. Do their reaction times have different means?
mean(english$RTlexdec[english$AgeSubject=="young"]
#The p-value is small, around 0.002. So there's not a very high chance that we would get a mean of 0.35 in one experiment from a coin that was really fair. Coin X is very unlikely to be a fair coin. We can reject the null hypothesis that Coin X has the same mean as a fair coin. (If we were doing this for real, we would want to do more than one experiment.)
#Let's try it with linguistics data. Going back to the "english" dataset, there are are two groups of subjects: young and old. Do their reaction times have different means?
mean(english$RTlexdec[english$AgeSubject=="young"])
#The p-value is small, around 0.002. So there's not a very high chance that we would get a mean of 0.35 in one experiment from a coin that was really fair. Coin X is very unlikely to be a fair coin. We can reject the null hypothesis that Coin X has the same mean as a fair coin. (If we were doing this for real, we would want to do more than one experiment.)
#Let's try it with linguistics data. Going back to the "english" dataset, there are are two groups of subjects: young and old. Do their reaction times have different means?
mean(english$RTlexdec[english$AgeSubject==young])
?english
#The p-value is small, around 0.002. So there's not a very high chance that we would get a mean of 0.35 in one experiment from a coin that was really fair. Coin X is very unlikely to be a fair coin. We can reject the null hypothesis that Coin X has the same mean as a fair coin. (If we were doing this for real, we would want to do more than one experiment.)
#Let's try it with linguistics data. Going back to the "english" dataset, there are are two groups of subjects: young and old. Do their reaction times have different means?
mean(english$RTlexdec[english$AgeSubject=="young"])
mean(english$RTlexdec[english$AgeSubject=="old"])
#They're a little different. Is that difference more likely to mean something real, or are the two groups probably really the same and the difference is due to chance?
#A t-test will help us, but first we need to make sure that the basic assumption holds: that the reaction times of the "young" group and the reaction times of the "old" group are approximately normally distributed.
hist(english$RTlexdec[english$AgeSubject=="young"])
hist(english$RTlexdec[english$AgeSubject=="old"])
#Hmm, they're a little bit skewed. That is, the mean isn't right in the middle, it's to the left. The t-test can still handle this okay, as long as we're working with enough data. Are we?
table(english$AgeSubject)
#Oh, yeah, that's plenty. If we only had like 30 observations, the skew would be a big problem, but with 2,000+ observations for each group, we're okay. So let's test.
t.test(english$RTlexdec[english$AgeSubject=="young"], english$RTlexdec[english$AgeSubject=="old"])
#Once again we can reject the null hypothesis: probably the difference in mean reaction time between these two groups is not due to chance. Probably young and old people in the whole population have different means here.
#Now, this is only STATISTICAL significance: it's probably not chance. That's not the same as SUBSTANTIVE significance. Substantive significance means noticing that the difference between these two means is only
6.66-6.44
#Hmm, they're a little bit skewed. That is, the mean isn't right in the middle, it's to the left. Let's look at a Q-Q plot to get a better idea of how far this is from a normal distribution.
qqplot(english$RTlexdec[english$AgeSubject=="young"])
#Hmm, they're a little bit skewed. That is, the mean isn't right in the middle, it's to the left. Let's look at a Q-Q plot to get a better idea of how far this is from a normal distribution.
qqplot(english$RTlexdec[english$AgeSubject=="young"], dist="norm")
#Hmm, they're a little bit skewed. That is, the mean isn't right in the middle, it's to the left. Let's look at a Q-Q plot to get a better idea of how far this is from a normal distribution.
qqPlot(english$RTlexdec[english$AgeSubject=="young"])
?qqplot
#Hmm, they're a little bit skewed. That is, the mean isn't right in the middle, it's to the left. Let's look at a Q-Q plot to get a better idea of how far this is from a normal distribution.
qqplot(y=english$RTlexdec[english$AgeSubject=="young"])
#Hmm, they're a little bit skewed. That is, the mean isn't right in the middle, it's to the left. Let's look at a Q-Q plot to get a better idea of how far this is from a normal distribution.
qqnorm(y=english$RTlexdec[english$AgeSubject=="young"])
qqnorm(english$RTlexdec[english$AgeSubject=="old"])
#Oh, yeah, that's plenty. If we only had like 30 observations, the skew would be a big problem, but with 2,000+ observations for each group, we're okay.
#That means we can go to the second assumption for a t-test: that the variances in the two groups are roughly the same. This is important because if like the young group is almost exactly around
#So let's test.
t.test(english$RTlexdec[english$AgeSubject=="young"], english$RTlexdec[english$AgeSubject=="old"])
#Oh, yeah, that's plenty. If we only had like 30 observations, the skew would be a big problem, but with 2,000+ observations for each group, we're okay.
#That means we can go to the second assumption for a t-test: that the variances in the two groups are roughly the same. This is important because if like the young group is almost all between 6.41 and 6.45, to get a mean of 6.43, but the old group is anywhere from 6.0 to 7.
6.66*2
#Oh, yeah, that's plenty. If we only had like 30 observations, the skew would be a big problem, but with 2,000+ observations for each group, we're okay.
#That means we can go to the second assumption for a t-test: that the variances in the two groups are roughly the same. This is important because if like the young group is almost all between 6.41 and 6.45, to get a mean of 6.43, but the old group is anywhere from 6.0 to 7.
.66*2
#Oh, yeah, that's plenty. If we only had like 30 observations, the skew would be a big problem, but with 2,000+ observations for each group, we're okay.
#That means we can go to the second assumption for a t-test: that the variances in the two groups are roughly the same. This is important because if like the young group is almost all between 6.41 and 6.45, to get a mean of 6.43, but the old group is anywhere from 6.0 to 7.32 to get the mean of 6.66, then there's something more weird going on and the t-test isn't going to notice it.
#If the two groups are both very normal, we can test variances with Bartlett's test.
?bartlett.test()
#Oh, yeah, that's plenty. If we only had like 30 observations, the skew would be a big problem, but with 2,000+ observations for each group, we're okay.
#That means we can go to the second assumption for a t-test: that the variances in the two groups are roughly the same. This is important because if like the young group is almost all between 6.41 and 6.45, to get a mean of 6.43, but the old group is anywhere from 6.0 to 7.32 to get the mean of 6.66, then there's something more weird going on and the t-test isn't going to notice it.
#If the two groups are both very normal, we can test variances with Bartlett's test.
var.test(english$RTlexdec[english$AgeSubject=="young"], english$RTlexdec[english$AgeSubject=="old"])
#Oh, yeah, that's plenty. If we only had like 30 observations, the skew would be a big problem, but with 2,000+ observations for each group, we're okay.
#That means we can go to the second assumption for a t-test: that the variances in the two groups are roughly the same. This is important because if like the young group is almost all between 6.41 and 6.45, to get a mean of 6.43, but the old group is anywhere from 6.0 to 7.32 to get the mean of 6.66, then there's something more weird going on and the t-test isn't going to notice it.
var(english$RTlexdec[english$AgeSubject=="young"])
var(english$RTlexdec[english$AgeSubject=="old"])
#Looks pretty close. If the two groups were both very normal, we could test variances with Bartlett's test (which is in base R). Ours aren't exactly normal, though, so let's use Levine's test. We need to get that from the "car" package.
install.packages("car")
library(car)
leveneTest(RTlexdec[english$AgeSubject=="young"] ~ RTlexdec[english$AgeSubject=="old"], data=english)
leveneTest(RTlexdec ~ AgeSubject, data=english)
#Well damn. The differences in variations are statistically significant. But like I said, R can handle this anyway. The default for a t-test in R is to assume that the variances are NOT equal. If they WERE equal, we could run a stricter t-test, but since they're not, we'll use the default.
#There's a third assumption that's important too: that the tests are independent.
?english
str(english)
#Well damn. The differences in variations are statistically significant. But like I said, R can handle this anyway. The default for a t-test in R is to assume that the variances are NOT equal. If they WERE equal, we could run a stricter t-test, but since they're not, we'll use the default.
#There's a third assumption that's important too: that the tests are independent. And that's also a little tricky here. See, we don't know how many subjects there are. The dataset doesn't say. Maybe each word was given to one and only one person, so there were 4568 subjects. Maybe there were only two subjects, a young one and an old one, and they each did each word several times. My guess is that each subject saw the whole set of 36 words, so:
4568/36
#Is this likely to be a fair coin? Well, a fair coin would have a mean around 0.5. It's definitely possible for us to get the mean we got here with a fair coin. That's our null hypothesis here:  Coin X is *really* a fair coin (mean=0.5), and the results we got (mean=0.35) are from chance. But is that very likely?
#We're gonna t-test to find out. But first, let's check our three assumptions.
# 1. Is the data normally distributed?
qqnorm(CoinX)
rbinom(n=1000, size=100, prob=0.35)
rbinom(n=100, size=100, prob=0.35)
#Let's stay with coin flips for an example. Say we have a new coin, Coin X, and we don't know if it's fair or not. We do one hundred experiments where we flip it 100 times and we get this results for the number of heads:
CoinX <- c(41, 37, 38, 37, 32, 25, 28, 38, 40, 28, 32, 41, 30, 37, 33, 38, 36, 33, 28, 33, 39, 35, 30, 38, 36, 41, 30, 33, 27, 31, 34, 43, 30, 37, 48, 32, 39, 38, 38, 36, 35, 41, 32, 42, 35, 38, 35, 34, 29, 38, 30, 36, 35, 45, 32, 36, 34, 35, 36, 44, 42, 33, 37, 34, 35, 30, 26, 32, 33, 37, 31, 48, 38, 36, 38, 42, 34, 34, 42, 31, 34, 35, 37, 34, 31, 32, 29, 39, 37, 36, 33, 36, 34, 32, 35, 36, 45, 42, 39, 34)
#What's the mean here?
mean(CoinX)
#Is Coin X likely to be a fair coin? Well, a fair coin would have a mean around 0.5, so in a hundred flips there would be about 50 heads. It's  possible for us to get the mean we got here with a fair coin. And that's our null hypothesis:  Coin X is *really* a fair coin (mean=0.5), and the results we got (mean=0.35) are from chance. But is that very likely?
#We're gonna t-test to find out. But first, let's check our three assumptions.
# 1. Is the data normally distributed?
qqnorm(CoinX)
#Looks ok. Wobbly at the edges but it's fine. And we know our "fair coin" comparison will be normal because we're gonna generate that ourselves.
qqnorm(rbinom(n=100,size=100,prob=0.5))
# 2. Are the variances the same?
bartlett.test(CoinX, rbinom(n=100,size=100,prob=0.5))
# 2. Are the variances the same?
bartlett.test(CoinX, rbinom(n=100,size=100,prob=0.5))
?bartlett.test
# 2. Are the variances the same?
bartlett.test(c(CoinX, rbinom(n=100,size=100,prob=0.5))
# 2. Are the variances the same?
bartlett.test(c(CoinX, rbinom(n=100,size=100,prob=0.5)))
# 2. Are the variances the same?
bartlett.test(c(CoinX, rbinom(n=100,size=100,prob=0.5)))
# 2. Are the variances the same?
var.test(CoinX, rbinom(n=100,size=100,prob=0.5))
#The variance differences are NOT statistically significant, which is what we want.
# 3. Are the tests independent?
#Well, sure. We already know that these are coin flips. Getting "heads" on flip #4 doesn't affect whether we get "heads" on flip #5, or #12, or #47. No problem there.
#So t-test is go. Are these two means different from each other in a statistically significant way?
t.test(CoinX, rbinom(n=100,size=100,prob=0.5))
