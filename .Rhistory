install.packages("rmarkdown")
library(rmarkdown)
?math
??math
17*17
##Set working directory (tell R what folder we're working in)
getwd()
#As always, start by setting up the working directory
getwd()
setwd("C:Users/Leah/RforLing")
#Next, import any packages you need. Since we'll be messing with a new dataset, we'll want "tidyverse." (You pretty much always want tidyverse.)
library(tidyverse)
#Download the Phoible inventory dataset: https://phoible.org/inventories
#Make sure you put the downloaded file in your working directory
#Then read the file in to R
data <- read.csv("Contributions.csv")
#We can pull the whole table
data
#Start by looking at the first 6 and last 6 rows
head(data)
tail(data)
data$name
data$name[,2000:2010]
data$name[2000:2010,]
data$name[1500:1510,]
data$name[,1500:1510]
data$name[1500:1510]
data$name[1700:1710]
data$name[1900:1910]
install.packages("LanguageR")
install.packages("languageR")
library(languageR)
?languageR
data(package="languageR")
lexdec
sizeRatings
head(english)
#Good grief that's a lot of columns
#What do they all mean?
#Let's look at the help file
?english
#So this dataset has a bunch of English words, information about those words, and how long the reaction time was for subjects to
english[english$CorrectLexdec>=90]
#So this dataset has a bunch of English words, information about those words, and how long the reaction time was for subjects to
english[english$CorrectLexdec>=50]
#So this dataset has a bunch of English words, information about those words, and how long the reaction time was for subjects to
english[english$CorrectLexdec>=30]
str(english)
#So this dataset has a bunch of English words, information about those words, and how long the reaction time was for subjects to
english[english$CorrectLexdec==30]
#So this dataset has a bunch of English words, information about those words, and how long the reaction time was for subjects to
english %>% filter(CorrectLexdec>=30)
#So this dataset has a bunch of English words, information about those words, and how long the reaction time was for subjects to
english %>% filter(CorrectLexdec<=5)
#So this dataset has a bunch of English words, information about those words, and how long the reaction time was for subjects to decide if it was a word or not. A bunch of the words are really obscure.
english %>% filter(CorrectLexdec>=30)
str(english)
#Both of these involve taking just the columns we need from all of these options
#For the first question, we want "Familiarity" and "RTlexdec"
#But wait!
#Every word is in here twice -- once with the "old" speakers and once with the "young" speakers
#Let's put them back together before we go on
#So we'll need the two columns of interest, plus "Word" and "AgeSubject"
#You pull particular columns from a dataframe using the "select()" function
#And we're gonna use piping, which comes from tidyverse
#That's stuff using this symbol: %>%
#With that, we can put the data first, then do something to it
english %>% select(RTlexdec,Familiarity,Word,AgeSubject)
#That's the same as this:
select(english, c(RTlexdec,Familiarity,Word,AgeSubject))
#Let's save the smaller dataset as a new variable
#You could save it as "english" again, but then you would *lose* anything you didn't keep
#So it's better to save it as a new variable, so "english" still has all the original information and we can go back and pull other stuff out later
q1data <- english %>% select(RTlexdec,Familiarity,Word,AgeSubject)
#Ok. Let's look at the structure of this smaller dataframe
str(q1data)
4569/2197
str(q1data$Word)
#Hmm. "Word" is saved as a factor with 2197 levels (that means there are 2197 different words). But there are 4568 total rows.
2197/4568
#Hmm. "Word" is saved as a factor with 2197 levels (that means there are 2197 different words). But there are 4568 total rows.
4568/2197
4568/2
#So some words are in here three or four times??
q1data %>% summarise(Word, n())
?summarize
#So some words are in here three or four times??
q1data %>% group_by(Word) %>% summarize(n())
#So some words are in here three or four times??
q1data %>% group_by(Word) %>% summarize(n()) %>% desc()
#So some words are in here three or four times??
q1data %>% group_by(Word) %>% summarize(count=n())
#So some words are in here three or four times??
q1data %>% group_by(Word) %>% summarize(count=n()) %>% filter(count>2)
#So some words are in here three or four times??
q1data %>% group_by(Word,AgeSubject) %>% summarize(count=n()) %>% filter(count>2)
#Looks like. That's weird.
#You could either drop these, or average all four reaction times together
#I'm gonna average them all together
q1data %>% group_by(Word) %>% summarize(avgRT=mean(RTlexdec))
#Once again, this just shows these summary numbers in the console for me
#To keep messing with this, I'll need to save it as a variable
#And since I'm removing data again by averaging, I'll make another new variable. Don't forget to keep "Familiarity" in there too!
#That should be the same for each word, no matter whether it's under "old" or "young," so I'll just take the first time it comes up
q1d2 <- q1data %>% group_by(Word) %>% summarize(avgRT=mean(RTlexdec, familiarity=first(Familiarity)))
head(q1d2)
#Once again, this just shows these summary numbers in the console for me
#To keep messing with this, I'll need to save it as a variable
#And since I'm removing data again by averaging, I'll make another new variable. Don't forget to keep "Familiarity" in there too!
#That should be the same for each word, no matter whether it's under "old" or "young," so I'll just take the first time it comes up
q1d2 <- q1data %>% group_by(Word) %>% summarize(avgRT=mean(RTlexdec, familiarity=mean(Familiarity)))
head(q1d2)
#Once again, this just shows these summary numbers in the console for me
#To keep messing with this, I'll need to save it as a variable
#And since I'm removing data again by averaging, I'll make another new variable. Don't forget to keep "Familiarity" in there too!
#That should be the same for each word, no matter whether it's under "old" or "young," so I'll just take the first time it comes up
q1d2 <- q1data %>% group_by(Word) %>% summarize(avgRT=mean(RTlexdec), familiarity=mean(Familiarity))
head(q1d2)
#Ok great!
#So the question: are these two correlated?
?correlation
#Ok great!
#So the question: are these two correlated?
??correlation
#Ok great!
#So the question: are these two correlated?
??corelation
#Ok great!
#So the question: are these two correlated?
??corelate
#Ok great!
#So the question: are these two correlated?
??correlate
#Ok great!
#So the question: are these two correlated?
??cov2cor
#Ok great!
#So the question: are these two correlated?
?cov2cor
#Ok great!
#So the question: are these two correlated?
q1d2 %>% cor(RTlexdec, familiarity)
head(q1d2)
#Ok great!
#So the question: are these two correlated?
q1d2 %>% cor(RTlexdec, y=familiarity)
#Ok great!
#So the question: are these two correlated?
q1d2 %>% cor(avgRT, familiarity)
#Ok great!
#So the question: are these two correlated?
q1d2 %>% cor(avgRT, y=familiarity)
#Ok great!
#So the question: are these two correlated?
cor(q1d2$avgRT, y=familiarity)
#Ok great!
#So the question: are these two correlated?
cor(q1d2$avgRT, y=q1d2$familiarity)
#Do young and old speakers have a statistically significant difference in average reaction time?
#Now we DO want separate info for young and old speakers, so we can't use the q1data variable we made before
#We need to go back to the original and get the data we need for this new question
#What were the original columns again?
str(english)
#Ok, so we just want "RTlexdec" and "AgeSubject"
q2data <- english %>% select(RTlexdec, AgeSubject)
head(q2data)
tail(q2data)
#And then let's get average reaction time by age
q2data %>% group_by(AgeSubject) %>% summarize(avgRT=mean(RTlexdec))
#And then let's get average reaction time by age
q2d2 <- q2data %>% group_by(AgeSubject) %>% summarize(avgRT=mean(RTlexdec))
q2d2
#aaaand a t-test:
?ttest
#aaaand a t-test:
?t.test()
#aaaand a t-test:
?t.test(q2d2$avgRT)
#aaaand a t-test:
t.test(q2d2$avgRT)
#aaaand a t-test:
t.test(q2d2$avgRT, y=q2d2$AgeSubject)
q2d2
#aaaand a t-test:
t.test(avgRT ~ AgeSubject, data=q2d2)
#aaaand a t-test:
t.test(RTlexdec ~ AgeSubject, data=q2data)
#Looks like there are some that show up 4 times. That's weird.
#You could either drop these, or average all the reaction times together
#I'm gonna drop them. I'd be more careful about it if this was a final analysis, but for now, I'm just taking a first look at the data and I  want to move forward.
#So I'll do the same thing as above, but filter to only get the rows that ARE 2
q1data %>% group_by(Word) %>% summarize(count=n()) %>% filter(count==2)
#Looks like there are some that show up 4 times. That's weird.
#You could either drop these, or average all the reaction times together
#I'm gonna drop them. I'd be more careful about it if this was a final analysis, but for now, I'm just taking a first look at the data and I  want to move forward.
#So I'll do the same thing as above, but filter to only get the rows that ARE 2
#And since this time I'm just dropping a few rows, I'll rewrite over the same variable name instead of making a new one
q1data <- q1data %>% group_by(Word) %>% summarize(count=n()) %>% filter(count==2)
q1data %>% group_by(AgeSubject) %>% summarize(mean(Familiarity))
#Let's save the smaller dataset as a new variable
#You could save it as "english" again, but then you would *lose* anything you didn't keep
#So it's better to save it as a new variable, so "english" still has all the original information and we can go back and pull other stuff out later
q1data <- english %>% select(RTlexdec,Familiarity,Word,AgeSubject)
#What we specifically want to know, though, is whether any of these counts are above 2
#So let's add one more step: filter()
q1data %>% group_by(Word) %>% summarize(count=n()) %>% filter(count>2)
#Looks like there are some that show up 4 times. That's weird.
#You could either drop these, or average all the reaction times together
#I'm gonna drop them. I'd be more careful about it if this was a final analysis, but for now, I'm just taking a first look at the data and I  want to move forward.
#So I'll do the same thing as above, but filter to only get the rows that ARE 2
#And since this time I'm just dropping a few rows, I'll rewrite over the same variable name instead of making a new one
q1data %>% group_by(Word) %>% summarize(count=n()) %>% filter(count==2)
q1data %>% group_by(AgeSubject) %>% summarize(mean(Familiarity))
#Looks like there are some that show up 4 times. That's weird.
#You could either drop these, or average all the reaction times together
#I'm gonna average them. I'd be more careful about it if this was a final analysis, but for now, I'm just taking a first look at the data and I  want to move forward.
#To get the reaction time averages, I group by word again, and this time take a mean() in the summarize() function
q1data %>% group_by(Word) %>% summarize(avgRT=mean(RTlexdec))
#What we specifically want to know, though, is whether any of these counts are above 2
#So let's add one more step: filter()
q1data %>% group_by(Word) %>% summarize(count=n()) %>% filter(count>2)
q1data[q1data$Word=="arm"]
q1data[q1data$Word=="arm",]
q1data[q1data$Word=="bitch",]
q1data[q1data$Word=="bust",]
#To get the reaction time averages, I group by word again, and this time take a mean() in the summarize() function
q1data %>% group_by(Word) %>% summarize(avgRT=mean(RTlexdec))
#Ok, practice time! Take 2 minutes to think of another fairly simple question we could ask about this data. Remember, you can look at the information on what all the variables are in help:
?english
